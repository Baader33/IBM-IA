{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8abd2f3a-7930-44bc-9a5f-3646677309bd",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_top\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \">\n",
    "</a> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b80864-134b-4e19-b978-042c3752181d",
   "metadata": {},
   "source": [
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork/image/IDSN-logo.png\" width=\"200\" alt=\"cognitiveclass.ai logo\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5bdfa8-6014-495e-af4c-1905a13cf122",
   "metadata": {},
   "source": [
    "<h1><h1>Pre-trained-Models with PyTorch </h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53741054-55b8-4d99-9976-6032dbb90087",
   "metadata": {},
   "source": [
    "In this lab, you will use pre-trained models to classify between the negative and positive samples; you will be provided with the dataset object. The particular pre-trained model will be resnet18; you will have three questions: \n",
    "<ul>\n",
    "<li>change the output layer</li>\n",
    "<li> train the model</li> \n",
    "<li>  identify  several  misclassified samples</li> \n",
    " </ul>\n",
    "You will take several screenshots of your work and share your notebook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3c08cf-34b0-406d-8125-0593277f34bc",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921f07a2-6a2d-4608-84f2-0cc62bf2501b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"#download_data\"> Download Data</a></li>\n",
    "    <li><a href=\"#auxiliary\"> Imports and Auxiliary Functions </a></li>\n",
    "    <li><a href=\"#data_class\"> Dataset Class</a></li>\n",
    "    <li><a href=\"#Question_1\">Question 1</a></li>\n",
    "    <li><a href=\"#Question_2\">Question 2</a></li>\n",
    "    <li><a href=\"#Question_3\">Question 3</a></li>\n",
    "</ul>\n",
    "<p>Estimated Time Needed: <strong>120 min</strong></p>\n",
    " </div>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceb7083-02ed-4c9c-b5b4-7b0418388a2a",
   "metadata": {},
   "source": [
    "<h2 id=\"download_data\">Download Data</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efedf9be-c643-4d62-8158-0918061c6b8b",
   "metadata": {},
   "source": [
    "Download the dataset and unzip the files in your data directory, unlike the other labs, all the data will be deleted after you close  the lab, this may take some time:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f119a703-4c0b-40c8-9ca9-152a26a98210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-08-04 12:28:29--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip\n",
      "Resolviendo s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
      "Conectando con s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)[67.228.254.196]:443... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 200 OK\n",
      "Longitud: 2598656062 (2,4G) [application/zip]\n",
      "Grabando a: «Positive_tensors.zip»\n",
      "\n",
      "Positive_tensors.zi 100%[===================>]   2,42G  13,3MB/s    en 3m 13s  \n",
      "\n",
      "2023-08-04 12:31:43 (12,8 MB/s) - «Positive_tensors.zip» guardado [2598656062/2598656062]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3f2804b-7bc0-4a34-a8bd-0756372003da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q Positive_tensors.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5119dc8-afc5-460d-879a-8b774f567bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-08-04 12:37:42--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
      "Resolviendo s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
      "Conectando con s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)[67.228.254.196]:443... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 200 OK\n",
      "Longitud: 2111408108 (2,0G) [application/zip]\n",
      "Grabando a: «Negative_tensors.zip»\n",
      "\n",
      "Negative_tensors.zi 100%[===================>]   1,97G  16,7MB/s    en 2m 9s   \n",
      "\n",
      "2023-08-04 12:39:52 (15,7 MB/s) - «Negative_tensors.zip» guardado [2111408108/2111408108]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
    "!unzip -q Negative_tensors.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad15709-e387-40fd-ab2f-8fde44dea3e1",
   "metadata": {},
   "source": [
    "We will install torchvision:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a4397a6-b3f6-4b0e-b9f9-c0e294eede06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp39-cp39-manylinux1_x86_64.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/edward/anaconda3/lib/python3.9/site-packages (from torchvision) (2.28.1)\n",
      "Collecting torch==2.0.1\n",
      "  Downloading torch-2.0.1-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:04\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/edward/anaconda3/lib/python3.9/site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: numpy in /home/edward/anaconda3/lib/python3.9/site-packages (from torchvision) (1.22.0)\n",
      "Requirement already satisfied: jinja2 in /home/edward/anaconda3/lib/python3.9/site-packages (from torch==2.0.1->torchvision) (2.11.3)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m930.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.0.0\n",
      "  Downloading triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/edward/anaconda3/lib/python3.9/site-packages (from torch==2.0.1->torchvision) (4.3.0)\n",
      "Requirement already satisfied: networkx in /home/edward/anaconda3/lib/python3.9/site-packages (from torch==2.0.1->torchvision) (2.8.4)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sympy in /home/edward/anaconda3/lib/python3.9/site-packages (from torch==2.0.1->torchvision) (1.10.1)\n",
      "Requirement already satisfied: filelock in /home/edward/anaconda3/lib/python3.9/site-packages (from torch==2.0.1->torchvision) (3.6.0)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel in /home/edward/anaconda3/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /home/edward/anaconda3/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision) (63.4.1)\n",
      "Collecting lit\n",
      "  Downloading lit-16.0.6.tar.gz (153 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.7/153.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cmake\n",
      "  Downloading cmake-3.27.0-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.0/26.0 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /home/edward/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/edward/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/edward/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/edward/anaconda3/lib/python3.9/site-packages (from requests->torchvision) (2022.9.14)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/edward/anaconda3/lib/python3.9/site-packages (from jinja2->torch==2.0.1->torchvision) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/edward/anaconda3/lib/python3.9/site-packages (from sympy->torch==2.0.1->torchvision) (1.2.1)\n",
      "Building wheels for collected packages: lit\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-16.0.6-py3-none-any.whl size=93584 sha256=74b70f132bad3b2e1d74e3114630f1f2a1d4dcf536e5effb5e75b2a6ee75bc20\n",
      "  Stored in directory: /home/edward/.cache/pip/wheels/a5/36/d6/cac2e6fb891889b33a548f2fddb8b4b7726399aaa2ed32b188\n",
      "Successfully built lit\n",
      "Installing collected packages: lit, cmake, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchvision\n",
      "Successfully installed cmake-3.27.0 lit-16.0.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 torchvision-0.15.2 triton-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720b2e1a-fa06-4daf-a922-4a70777f6709",
   "metadata": {},
   "source": [
    "<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cadbf87-12b4-4cf5-973b-d074375b21f7",
   "metadata": {},
   "source": [
    "The following are the libraries we are going to use for this lab. The <code>torch.manual_seed()</code> is for forcing the random function to give the same number every time we try to recompile it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "100c4913-0f97-425c-bf42-eba819ed5f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f24f4364790>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the libraries will be used for this lab.\n",
    "\n",
    "from PIL import Image\n",
    "import pandas\n",
    "import time\n",
    "import torch \n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "import os\n",
    "import glob\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62927ada-7de8-485c-a08e-cb2b038b25d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fed9c29-48b2-4bbf-9ba9-7f6fc1c088a2",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b81ceb-2ff9-4e71-b0ad-bcd507f91029",
   "metadata": {},
   "source": [
    "<h2 id=\"data_class\">Dataset Class</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8630dc80-3ee1-40a4-84d7-0427cd7101c7",
   "metadata": {},
   "source": [
    " This dataset class is essentially the same dataset you build in the previous section, but to speed things up, we are going to use tensors instead of jpeg images. Therefor for each iteration, you will skip the reshape step, conversion step to tensors and normalization step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c2612bc-5ed4-4f7d-bc9d-71c6a69ce2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Create your own dataset object\n",
    "\n",
    "class Dataset(Dataset):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self,transform=None,train=True):\n",
    "        directory=\"/home/edward/IBM-IA/DL-Capstone\"\n",
    "        positive=\"Positive_tensors\"\n",
    "        negative='Negative_tensors'\n",
    "\n",
    "        positive_file_path=os.path.join(directory,positive)\n",
    "        negative_file_path=os.path.join(directory,negative)\n",
    "        positive_files=[os.path.join(positive_file_path,file) for file in os.listdir(positive_file_path) if file.endswith(\".pt\")]\n",
    "        negative_files=[os.path.join(negative_file_path,file) for file in os.listdir(negative_file_path) if file.endswith(\".pt\")]\n",
    "        number_of_samples=len(positive_files)+len(negative_files)\n",
    "        self.all_files=[None]*number_of_samples\n",
    "        self.all_files[::2]=positive_files\n",
    "        self.all_files[1::2]=negative_files \n",
    "        # The transform is goint to be used on image\n",
    "        self.transform = transform\n",
    "        #torch.LongTensor\n",
    "        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n",
    "        self.Y[::2]=1\n",
    "        self.Y[1::2]=0\n",
    "        \n",
    "        if train:\n",
    "            self.all_files=self.all_files[0:30000]\n",
    "            self.Y=self.Y[0:30000]\n",
    "            self.len=len(self.all_files)\n",
    "        else:\n",
    "            self.all_files=self.all_files[30000:]\n",
    "            self.Y=self.Y[30000:]\n",
    "            self.len=len(self.all_files)     \n",
    "       \n",
    "    # Get the length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, idx):\n",
    "               \n",
    "        image=torch.load(self.all_files[idx])\n",
    "        y=self.Y[idx]\n",
    "                  \n",
    "        # If there is any transform method, apply it onto the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, y\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747173bb-89d3-45e8-b058-ab209f14610c",
   "metadata": {},
   "source": [
    "We create two dataset objects, one for the training data and one for the validation data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03d6186-c5e3-4594-b469-fc776d407fe5",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_1\">Question 1</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c3bc6f-c9ce-4bc6-98e2-160b4c2c6be3",
   "metadata": {},
   "source": [
    "<b>Prepare a pre-trained resnet18 model :</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdd3ebc-0de2-4418-9316-a20a12ec7034",
   "metadata": {},
   "source": [
    "<b>Step 1</b>: Load the pre-trained model <code>resnet18</code> Set the parameter <code>pretrained</code> to true:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "293cde0f-d36f-4584-a1ff-d4fe736b9fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the pre-trained model resnet18\n",
    "\n",
    "model = models.resnet18(pretrained = True)\n",
    "\n",
    "mean = [.485, .456, .406]\n",
    "std = [.229, .224, .225]\n",
    "\n",
    "composed = transforms.Compose([transforms.Resize(224),\n",
    "                               transforms.ToPILImage(),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize(mean, std)])\n",
    "\n",
    "train_dataset = Dataset(transform = composed, train = True)\n",
    "validation_dataset = Dataset(transform = composed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b310a4-2eb5-4627-ae5e-d0783ba838ad",
   "metadata": {},
   "source": [
    "<b>Step 2</b>: Set the attribute <code>requires_grad</code> to <code>False</code>. As a result, the parameters will not be affected by training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22ed14f3-ded5-47a6-b667-34e9d5bc0b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Set the parameter cannot be trained for the pre-trained model\n",
    "\n",
    "#Step required for can modify the last layer and output layer\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f23176-eca4-4e8f-9ec2-a164a5a7ef65",
   "metadata": {},
   "source": [
    "<code>resnet18</code> is used to classify 1000 different objects; as a result, the last layer has 1000 outputs.  The 512 inputs come from the fact that the previously hidden layer has 512 outputs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 3</b>: Replace the output layer <code>model.fc</code> of the neural network with a <code>nn.Linear</code> object, to classify 2 different classes. For the\n",
    "parameters <code>in_features </code> remember the last hidden layer has 512 neurons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f79a8c7-4e3c-48b2-8d5c-75ec66fc7b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(512, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048fe114-92ee-4c41-aede-1e016711ffcd",
   "metadata": {},
   "source": [
    "Print out the model in order to show whether you get the correct answer.<br> <b>(Your peer reviewer is going to mark based on what you print here.)</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1462f12b-da03-4175-ad74-043e46166410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb183bcf-8cfa-4e48-93e8-af78f42e57b0",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_2\">Question 2: Train the Model</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91768582-592a-4360-b47c-1c7db7008ff8",
   "metadata": {},
   "source": [
    "In this question you will train your, model:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8455f1a9-a0af-4502-9179-0a4693cf06d8",
   "metadata": {},
   "source": [
    "<b>Step 1</b>: Create a cross entropy criterion function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5263c76f-483d-42bf-9716-c526278d3fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create the loss function\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14f9645-a2ff-4900-91e7-4acf3eec2427",
   "metadata": {},
   "source": [
    "<b>Step 2</b>: Create a training loader and validation loader object, the batch size should have 100 samples each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f006c789-b1d6-4eb9-bdc4-613265ac440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_dataset, batch_size = 100)\n",
    "validation_loader = DataLoader(dataset = validation_dataset, batch_size = 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a965344-294c-4f35-881b-6f3b7e938149",
   "metadata": {},
   "source": [
    "<b>Step 3</b>: Use the following optimizer to minimize the loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ffbf141-4354-429f-ba64-cf0fecf4d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([parameters  for parameters in model.parameters() if parameters.requires_grad],lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278f8e4c-8cc9-477a-b291-3aedf0d0852e",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7f9e3b-f4a4-430d-92e4-2b204f4f9162",
   "metadata": {},
   "source": [
    "**Complete the following code to calculate  the accuracy on the validation data for one epoch; this should take about 45 minutes. Make sure you calculate the accuracy on the validation data.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e10db4f0-56f4-4c94-940f-133f5764ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=1\n",
    "loss_list=[]\n",
    "accuracy_list=[]\n",
    "correct=0\n",
    "N_test=len(validation_dataset)\n",
    "N_train=len(train_dataset)\n",
    "start_time = time.time()\n",
    "#n_epochs\n",
    "\n",
    "Loss=0\n",
    "start_time = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    loss_sublist = []\n",
    "    for x, y in train_loader:\n",
    "\n",
    "        model.train() \n",
    "        #clear gradient\n",
    "        optimizer.zero_grad()\n",
    "        #make a prediction \n",
    "        z = model(x)\n",
    "        # calculate loss\n",
    "        loss = criterion(z, y)\n",
    "        loss_sublist.append(loss.data.item())\n",
    "        loss.backward()\n",
    "        # calculate gradients of parameters \n",
    "        optimizer.step()    \n",
    "        # update parameters \n",
    "        loss_list.append(loss.data)\n",
    "    loss_list.append(np.mean(loss_sublist))\n",
    "    correct=0\n",
    "    for x_test, y_test in validation_loader:\n",
    "        # set model to eval \n",
    "        model.eval()\n",
    "        #make a prediction\n",
    "        z = model(x_test)\n",
    "        #find max \n",
    "        _,yhat = torch.max(z.data, 1)\n",
    "       \n",
    "       \n",
    "        #Calculate misclassified  samples in mini-batch \n",
    "        correct+=(yhat==y_test).sum().item()\n",
    "        \n",
    "    accuracy=correct/N_test\n",
    "    accuracy_list.append(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176f3003-c65d-40bc-96ad-5c9c48c99f3b",
   "metadata": {},
   "source": [
    "<b>Print out the Accuracy and plot the loss stored in the list <code>loss_list</code> for every iteration and take a screen shot.</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f321eee5-544b-4659-839f-0e6ea591d09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9446444644464447"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c7ae1d7-abbd-4e21-b0f2-9e45b967a1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj0AAAGwCAYAAABCV9SaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABG3ElEQVR4nO3dd3iUZb7G8Xtm0kMSSIAUCEko0puAGoqgKAjYVt3F3taCS1N0C5a17K541FVEFFZXRdeGCmIBUVCKCIiUSOihJRESQgKk15n3/BEyGEMNM/NOMt/Pdc0leeedmV+ew2HufarFMAxDAAAAjZzV7AIAAAA8gdADAAB8AqEHAAD4BEIPAADwCYQeAADgEwg9AADAJxB6AACAT/AzuwBPczgc2r9/v8LCwmSxWMwuBwAAnAbDMFRYWKi4uDhZrfXrs/G50LN//37Fx8ebXQYAAKiHzMxMtW7dul6v9bnQExYWJqm60cLDw02uBgAAnI6CggLFx8c7v8frw+dCT82QVnh4OKEHAIAG5mympjCRGQAA+ARCDwAA8AmEHgAA4BMIPQAAwCcQegAAgE8g9AAAAJ9A6AEAAD6B0AMAAHwCoQcAAPgEQg8AAPAJhB4AAOATCD0AAMAnEHpcxO4wlFNYpt0Hi8wuBQAAHAehx0X2HynVef/6ViNe+t7sUgAAwHEQelwkPNhfklRe5VBZpd3kagAAwG8RelwkLNBPFkv1nwtKK80tBgAA1EHocRGr1aLwoOrenoIyQg8AAN6G0ONCEUeHuPLp6QEAwOsQelyI0AMAgPci9LgQoQcAAO9F6HEhZ+gpIfQAAOBtCD0uFO7s6akyuRIAAPBbhB4XYngLAADvRehxIUIPAADei9DjQoQeAAC8F6HHhWpCDzsyAwDgfQg9LkRPDwAA3ovQ40KEHgAAvBehx4XCg/0kEXoAAPBGhB4XqunpKa20q6LKYXI1AADg1wg9LhR29JR1id4eAAC8DaHHhWxWi8KCGOICAMAbEXpcjMnMAAB4J0KPi7FXDwAA3onQ42LO0FNG6AEAwJsQelyM4S0AALwTocfFnKGnhNADAIA3IfS4GD09AAB4J0KPi4UTegAA8EqEHhejpwcAAO9E6HExQg8AAN6J0ONihB4AALwTocfF2JwQAADvROhxMXp6AADwToQeF6sJPcUVdlXaHSZXAwAAahB6XKxmybrEEBcAAN6E0ONiNqtFYYF+khjiAgDAmxB63IANCgEA8D6EHjcg9AAA4H0IPW4QEczwFgAA3obQ4wbs1QMAgPch9LgBe/UAAOB9CD1u4OzpKasyuRIAAFCD0OMGzp6eEnp6AADwFoQeN2B4CwAA70PocQOWrAMA4H0IPW5ATw8AAN6H0OMGhB4AALwPoccN2KcHAADvQ+hxg5rQU1heJbvDMLkaAAAgEXrcomYis0RvDwAA3oLQ4wb+NqtCA2ySmNcDAIC3IPS4CZOZAQDwLoQeN2GvHgAAvAuhx03o6QEAwLuYGnqmTJmifv36KSwsTC1bttTVV1+t7du3n/J1y5YtU58+fRQUFKS2bdtq5syZHqj2zBB6AADwLqaGnmXLlmns2LFavXq1Fi1apKqqKg0bNkzFxcUnfM2ePXs0cuRIDRo0SBs2bNDDDz+sCRMmaM6cOR6s/NQY3gIAwLv4mfnhCxcurPXzW2+9pZYtW2rdunW68MILj/uamTNnqk2bNpo6daokqXPnzlq7dq2ef/55XXvtte4u+bSxQSEAAN7Fq+b05OfnS5IiIyNPeM+qVas0bNiwWteGDx+utWvXqrKybsAoLy9XQUFBrYcnMLwFAIB38ZrQYxiGJk2apIEDB6pbt24nvC87O1vR0dG1rkVHR6uqqkq5ubl17p8yZYoiIiKcj/j4eJfXfjyEHgAAvIvXhJ5x48Zp48aN+uCDD055r8ViqfWzYRjHvS5JkydPVn5+vvORmZnpmoJPwTm8VUboAQDAG5g6p6fG+PHj9fnnn2v58uVq3br1Se+NiYlRdnZ2rWs5OTny8/NTVFRUnfsDAwMVGBjo0npPBz09AAB4F1N7egzD0Lhx4zR37lx99913SkpKOuVrkpOTtWjRolrXvvnmG/Xt21f+/v4neJXnsXoLAADvYmroGTt2rN599129//77CgsLU3Z2trKzs1VaWuq8Z/Lkybr11ludP48ZM0bp6emaNGmStm7dqjfffFNvvPGGHnroITN+hRNy9vSUEHoAAPAGpoaeGTNmKD8/X0OGDFFsbKzzMXv2bOc9WVlZysjIcP6clJSkBQsWaOnSperVq5f+8Y9/aNq0aV61XF06FnoKy6vkcBgmVwMAAEyd01MzAflkZs2aVefa4MGDtX79ejdU5Do1occwpMKyKkWEeM/QGwAAvshrVm81NgF+VgX72yQxrwcAAG9A6HEjVnABAOA9CD1uROgBAMB7EHrciNADAID3IPS4EXv1AADgPQg9bkRPDwAA3oPQ40aEHgAAvAehx40IPQAAeA9CjxtFBFfv/VhA6AEAwHSEHjdiIjMAAN6D0ONGDG8BAOA9CD1uROgBAMB7EHrcqCb0FJQRegAAMBuhx42coae0Ug7HqU+UBwAA7kPocaOaicwOQyqqqDK5GgAAfBuhx42C/G0K9Ktu4vwShrgAADATocfNmMwMAIB3IPS42a/n9QAAAPMQetyMnh4AALwDocfNCD0AAHgHQo+bEXoAAPAOhB434/wtAAC8A6HHzejpAQDAOxB63IzQAwCAdyD0uBmhBwAA70DocTP26QEAwDsQetwsIoSeHgAAvAGhx83Cgwg9AAB4A0KPmzmHt8qqZBiGydUAAOC7CD1uVhN67A5DReVVJlcDAIDvIvS4WZC/VQG26mYuKCP0AABgFkKPm1kslmO7MpcwrwcAALMQejwgIthPEpOZAQAwE6HHA9igEAAA8xF6PIANCgEAMB+hxwPo6QEAwHyEHg8g9AAAYD5CjwcQegAAMB+hxwPCCT0AAJiO0OMBTUMCJEmHSypMrgQAAN9F6PGAmPAgSdKBgjKTKwEAwHcRejwgtml16Nl3uJRDRwEAMAmhxwPiIoIlScUVds7fAgDAJIQeDwgOsCkytHpez/4jpSZXAwCAbyL0eEjc0SEuQg8AAOYg9HhIzRAXoQcAAHMQejwkrunR0JPPCi4AAMxA6PEQhrcAADAXocdDnD09hB4AAExB6PGQY6GH4S0AAMxA6PGQVkdDT3ZBmarsDpOrAQDA9xB6PKRFk0D52yyyOwzlFJabXQ4AAD6H0OMhVqtFMRHVk5mz8pnXAwCApxF6PCj26F49+5jXAwCAxxF6PKgVK7gAADANoceD2KsHAADzEHo8iL16AAAwD6HHg2pCD3N6AADwPEKPB9XM6WH1FgAAnkfo8aDYo0vWj5RUqri8yuRqAADwLYQeDwoL8ldYkJ8kensAAPA0Qo+HtWJeDwAApiD0eBgruAAAMAehx8PYqwcAAHMQejzsWE8Pw1sAAHiSqaFn+fLluuKKKxQXFyeLxaJ58+ad9P6lS5fKYrHUeWzbts0zBbtAXATDWwAAmMHPzA8vLi5Wz549dccdd+jaa6897ddt375d4eHhzp9btGjhjvLcwtnTw+otAAA8ytTQM2LECI0YMeKMX9eyZUs1bdr0tO4tLy9XeXm58+eCgoIz/jxXqpnTk3WkTA6HIavVYmo9AAD4igY5p6d3796KjY3V0KFDtWTJkpPeO2XKFEVERDgf8fHxHqry+KLDg2S1SBV2h3KLy0/9AgAA4BINKvTExsbqtdde05w5czR37lx17NhRQ4cO1fLly0/4msmTJys/P9/5yMzM9GDFdfnbrIoOr1nBxWRmAAA8xdThrTPVsWNHdezY0flzcnKyMjMz9fzzz+vCCy887msCAwMVGBjoqRJPS1zTYGXll2n/kVL1im9qdjkAAPiEBtXTczwXXHCB0tLSzC7jjNScwcUKLgAAPKfBh54NGzYoNjbW7DLOSCv26gEAwONMHd4qKirSzp07nT/v2bNHKSkpioyMVJs2bTR58mTt27dP77zzjiRp6tSpSkxMVNeuXVVRUaF3331Xc+bM0Zw5c8z6FeqFoygAAPA8U0PP2rVrddFFFzl/njRpkiTptttu06xZs5SVlaWMjAzn8xUVFXrooYe0b98+BQcHq2vXrpo/f75Gjhzp8drPBnv1AADgeRbDMAyzi/CkgoICRUREKD8/v9YGh560eX++Rk1boeZNArT20UtNqQEAgIbEFd/fDX5OT0NUM6cnt6hCZZV2k6sBAMA3EHpMEBHsr2B/myQpO5/JzAAAeAKhxwQWi8V5HAWTmQEA8AxCj0lqJjPvI/QAAOARhB6TsFcPAACeRegxCXv1AADgWYQek7BXDwAAnkXoMUkc528BAOBRhB6TxP1qTo+P7Q8JAIApCD0miTna01NaadeRkkqTqwEAoPEj9JgkyN+m5k0CJbFsHQAATyD0mKgVGxQCAOAxhB4TsWwdAADPIfSYKDaiOvRkcf4WAABuR+gxUc35W8zpAQDA/Qg9JmrF8BYAAB5D6DFRHOdvAQDgMYQeE9WEngOFZaq0O0yuBgCAxo3QY6Ko0AAF+FllGFI2k5kBAHArQo+JrFaLYo/uzMwKLgAA3IvQY7K4CCYzAwDgCfUKPW+//bbmz5/v/Pkvf/mLmjZtqv79+ys9Pd1lxfmCVs2qQ88vh0tMrgQAgMatXqHn6aefVnBw9Zf1qlWrNH36dD377LNq3ry5HnjgAZcW2Ni1iQyRJKXnEXoAAHAnv/q8KDMzU+3bt5ckzZs3T9ddd53uueceDRgwQEOGDHFlfY1eQtTR0HOI0AMAgDvVq6enSZMmysvLkyR98803uuSSSyRJQUFBKi1lbsqZONbTU2xyJQAANG716um59NJLddddd6l3797asWOHRo0aJUnavHmzEhMTXVlfo5cYFSpJOlBQrrJKu4L8bSZXBABA41Svnp5XXnlFycnJOnjwoObMmaOoqChJ0rp163TDDTe4tMDGrmmIv8KCqrNnBkNcAAC4Tb16epo2barp06fXuf7kk0+edUG+xmKxKCEqRJv2FSg9r0TnRIeZXRIAAI1SvXp6Fi5cqBUrVjh/fuWVV9SrVy/deOONOnz4sMuK8xUJkdVDXMzrAQDAfeoVev785z+roKBAkpSamqoHH3xQI0eO1O7duzVp0iSXFugL2hxdwcXwFgAA7lOv4a09e/aoS5cukqQ5c+bo8ssv19NPP63169dr5MiRLi3QFyQeDT172asHAAC3qVdPT0BAgEpKqr+gFy9erGHDhkmSIiMjnT1AOH1tjg5vZTC8BQCA29Srp2fgwIGaNGmSBgwYoDVr1mj27NmSpB07dqh169YuLdAX1GxQ+MvhUlXZHfKzcSQaAACuVq9v1+nTp8vPz0+ffPKJZsyYoVatWkmSvvrqK1122WUuLdAXxIQHKcDPqiqHwWnrAAC4Sb16etq0aaMvv/yyzvUXX3zxrAvyRVarRfHNgrXrYLHS80oUf3SXZgAA4Dr1Cj2SZLfbNW/ePG3dulUWi0WdO3fWVVddJZuNHYXrIyEqVLsOFmtvXrEGdmhudjkAADQ69Qo9O3fu1MiRI7Vv3z517NhRhmFox44dio+P1/z589WuXTtX19noJbBsHQAAt6rXnJ4JEyaoXbt2yszM1Pr167VhwwZlZGQoKSlJEyZMcHWNPiGBg0cBAHCrevX0LFu2TKtXr1ZkZKTzWlRUlJ555hkNGDDAZcX5koSoml2Z6ekBAMAd6tXTExgYqMLCwjrXi4qKFBAQcNZF+aJf78psGIbJ1QAA0PjUK/Rcfvnluueee/Tjjz/KMAwZhqHVq1drzJgxuvLKK11do09o3SxYFotUUmHXwaJys8sBAKDRqVfomTZtmtq1a6fk5GQFBQUpKChI/fv3V/v27TV16lQXl+gbAv1siosIliRlMMQFAIDL1WtOT9OmTfXZZ59p586d2rp1qwzDUJcuXdS+fXtX1+dTEqJCtO9IqdLzStQ3MfLULwAAAKfttEPPqU5PX7p0qfPPL7zwQr0L8mUJUSFauStP6SxbBwDA5U479GzYsOG07rNYLPUuxtdx8CgAAO5z2qFnyZIl7qwDOrZB4V7m9AAA4HIc5+1F2kSyKzMAAO5C6PEiNT09h4orVFhWaXI1AAA0LoQeLxIW5K+o0OrNHdmZGQAA1yL0eJk2HDwKAIBbEHq8TM3Bo3tZwQUAgEsRerxMm6iaZev09AAA4EqEHi9T09PDnB4AAFyL0ONlEpszpwcAAHcg9HiZml2Z9+eXqrzKbnI1AAA0HoQeL9O8SYBCAmwyDCnzUKnZ5QAA0GgQeryMxWL51c7MrOACAMBVCD1eqGZnZiYzAwDgOoQeL5RwdNk6oQcAANch9HihBHZlBgDA5Qg9Xijh6AoudmUGAMB1CD1eqKan55dDpbI7DJOrAQCgcSD0eKHYiCD5WS2qsDuUXVBmdjkAADQKhB4v5GezqnWzYElSOkNcAAC4BKHHSyVw8CgAAC5lauhZvny5rrjiCsXFxclisWjevHmnfM2yZcvUp08fBQUFqW3btpo5c6b7CzVBzbyevYQeAABcwtTQU1xcrJ49e2r69Omndf+ePXs0cuRIDRo0SBs2bNDDDz+sCRMmaM6cOW6u1PPYlRkAANfyM/PDR4wYoREjRpz2/TNnzlSbNm00depUSVLnzp21du1aPf/887r22muP+5ry8nKVl5c7fy4oKDirmj2FDQoBAHCtBjWnZ9WqVRo2bFita8OHD9fatWtVWVl53NdMmTJFERERzkd8fLwnSj1rzg0K80pkGCxbBwDgbDWo0JOdna3o6Oha16Kjo1VVVaXc3Nzjvmby5MnKz893PjIzMz1R6lmrGd4qLK/S4ZLjBzoAAHD6GlTokapPIf+1ml6Q316vERgYqPDw8FqPhiDI3+Zctp6SedjkagAAaPgaVOiJiYlRdnZ2rWs5OTny8/NTVFSUSVW5z0UdW0qSFm05YHIlAAA0fA0q9CQnJ2vRokW1rn3zzTfq27ev/P39TarKfYZ1rR7KW7TlAMdRAABwlkwNPUVFRUpJSVFKSoqk6iXpKSkpysjIkFQ9H+fWW2913j9mzBilp6dr0qRJ2rp1q95880298cYbeuihh8wo3+3OT4pSWJCfcosqGOICAOAsmRp61q5dq969e6t3796SpEmTJql37976+9//LknKyspyBiBJSkpK0oIFC7R06VL16tVL//jHPzRt2rQTLldv6AL8rLq4U/UQ1zebGeICAOBsWAwfWw9dUFCgiIgI5efnN4hJzfM3Zmns++uVGBWiJQ8NOeGEbQAAGjNXfH83qDk9vmhwxxYK8LNqb16J0nKKzC4HAIAGi9Dj5ZoE+mlg++aSpG82Z5/ibgAAcCKEngZgWJfqVVzfsHQdAIB6I/Q0AEM7R8tikTb+kq/9R0rNLgcAgAaJ0NMAtAgLVJ82zSRJi7fS2wMAQH0QehqImo0KWboOAED9EHoaiGFdYiRJq3fnKZ8DSAEAOGOEngYisXmoOkaHqcph6Lvt9PYAAHCmCD0NCENcAADUH6GnAakZ4lq246DKKu0mVwMAQMNC6GlAurUKV1xEkEoq7PphZ67Z5QAA0KAQehoQi8WiYV2re3sY4gIA4MwQehqYmt2ZF289ILvDp86KBQDgrBB6Gph+SZGKCPZXXnGF1mccNrscAAAaDEJPA+Nvs2pop5aSpK83cQApAACni9DTANUsXZ+fmqXyKlZxAQBwOgg9DdCQji0VHR6orPwyvb1yr9nlAADQIBB6GqAgf5v+PLyTJOnlb3cqr6jc5IoAAPB+hJ4G6prerdStVbgKy6s0dXGa2eUAAOD1CD0NlNVq0SMju0iS3l+TobQDhSZXBACAdyP0NGDJ7aI0rEu07A5DTy/YanY5AAB4NUJPAzd5ZGf52yxasv2glu84aHY5AAB4LUJPA5fUPFS3JidKkv41f6uq7A5zCwIAwEsRehqBCRd3UNMQf20/UKiP1v5idjkAAHglQk8jEBHir4lDO0iSXli0XYVllSZXBACA9yH0NBI3X5Cgts1DlVtUoRlLd5ldDgAAXofQ00j426yaPLKzJOm/K/Yo81CJyRUBAOBdCD2NyCWdW6p/uyhVVDl02dTlevyzTdp1sMjssgAA8AqEnkbEYrHoX7/rrg4tm6i4wq63V6Vr6L+X6dY31+i7bQfkcBhmlwgAgGkshmH41DdhQUGBIiIilJ+fr/DwcLPLcQvDMLRiZ67eXrlX327LUc3/hROiQnRbcqJuSU6Qv428CwBoOFzx/U3oaeQy8kr0zqq9mr02U4VlVZKkC9pG6tWb+igyNMDk6gAAOD2EnnrwtdBTo6SiSnPW/aJnvtqm4gq74iOD9d9b+6ljTJjZpQEAcEqu+P5mjMNHhAT46ZbkRH06doDaRIYo81Cprnn1By3acsDs0gAA8AhCj485JzpMn40doOS2USqusOue/63VK0t2ysc6/AAAPojQ44OahQbonT+ep1uTE2QY0nNfb9eED1NUWmE3uzQAANyG0OOj/G1WPXVVN/3rd93kZ7Xoi5/368rpKzT7pwyVVFSZXR4AAC7HRGbox915uu+99TpUXCFJCgv00zXnttKN5ycw0RkA4BVYvVUPhJ7jO1RcoY/XZur9NRlKzzt2hEW/xGa68fw2Sm7bXM1C/RXoZzvhe+SXVio9r1h780qUnlssP5tVN1/QRmFB/p74FQAAjRihpx4IPSfncBj6YVeu3v8xQ99sOSD7b3ZxDg2wqVlogCKPPkID/LQ/v1TpeSXOnqJfi48M1tTRvdQnIdJTvwIAoBEi9NQDoef0HSgo00c/ZWruhn3KPFSiqtM4xqJ5k0AlNQ9Rm8hQ/bgnT78cLpXVIo2/uIPGX9xefuwEDQCoB0JPPRB66scwDBWUVelwcYUOlVTocHGF8oorVFhWpdiIICVEhSghKlRNAv2crykoq9Tjn23Wpxv2SZLObdNUU0f3VpuoELN+DQBAA0XoqQdCj+d9lrJPj366SYXlVWoS6Kenruqq3/VuJYvFYnZpAIAGgh2Z0SBc1auVFkwcpH6JzVRUXqVJH/2syXNT2RARAOBRhB54RHxkiD64+wI9eOk5slkt+vCnTP2455DZZQEAfAihBx7jZ7Nq/NAOur5fvCTp1aW7TK4IAOBLCD3wuHsvbCerRVq+46A27cs3uxwAgI8g9MDj2kSF6PIecZKkGfT2AAA8hNADU9w3pJ0kacGmLO0+WGRyNQAAX0DogSk6x4br4k4tZRjSf5btNrscAIAPIPTANH862tszd8Mvys4vM7kaAEBjR+iBafomRuq8xEhV2g3993t6ewAA7kXoganuu6i6t+f9NRk6fJwDSwEAcBVCD0w15JwW6hIbrpIKu95etfeE96XnFevd1ekqLKv0XHEAgEaF0ANTWSwW50quWSv3qri8qtbzxeVVenbhNl36wnI9Om+T7pz1k8oq7af9/jmFZSr6zXsCAHwToQemG9k9VolRITpSUqkP1mRIqj7V/bOUfRr672V6dekuVdgdslkt+mnvYU34YIPsjlOf27UgNUsDn1miwc8u0cZfjrj5twAAeDtCD0xns1p07+Dq3p7/fr9HP2ce0ej/rNbED1OUXVCm+MhgvXZLH71/1/kK8LPqmy0H9Nhnm056YOkHazI09v31qrA7lFdcoetfW60l23M89SsBALyQxfCxo65dcTQ9XK+8yq4Ln12iAwXlzmtB/laNHdJed1/YVkH+NknSwk1Zuu+99TIM6YFLztHESzrUeh/DMDRj2S49u3C7JOn6fvHad6RU36flyma16Jlruuv3feM994sBAFzCFd/f9PTAKwT62XTXwLbOny/vEavvHhyi8UM7OAOPJF3WLVZPXdVNkvTi4h3O4TCpOvBM+WqbM/CMvaidplzTXW/c1k+/691KdoehP3+yUa8s2XnSXiIAQOPkZ3YBQI07BiQqKMCmjtFhOi8p8oT33XJBgnIKyvTydzv1yKepigoN0MWdWmry3FR9vO4XSdKjozrrrkHVISrAz6J//76nosODNHPZLj339XZl55fpiSu7yma1uKz+vKJyhQb61QppAADvwfAWGiTDMPS3OamavTZTgX5W9UloppW78k45hDXrhz168sstMgxpWJdo/XFgkirthirtDlXYHdX/rXLI32bVwPbN1Sw04JR1rE0/rP8s26XFW3PUL7GZPro3WRaL68IUAMA139+EHjRYVXaH7v3fOn27rXqCcoCfVdNv6K1hXWNO+rr5G7P0wOwUVdgdJ73Pz2rRgPbNdXmPWA3rGqOIYH/ncw6HoUVbD+g/y3ZpfcaRWq+beXMfXdbt5DUAAM4MoaceCD2NS2mFXXe/s1Zbswo0/cZzldwu6rRe9+PuPD391TYVlVXK32ZVgJ9V/jar/G0W+dusOlhYrm3Zhc77A2xWXXhOc13eI05llXa99v1u7T5Y7Hzu2j6tJEkfrMlUx+gwfTVxkKwuHDoDAF9H6KkHQk/jYxiG7A5DfjbXzsvfdbBIX/6cpS837ldaTlGd58OD/HTzBQm6fUCiWoYFKb+kUgP/7zsVlldp+o29dXmPOJfWAwC+jNBTD4Qe1Mf27EJ9uXG/FqRmyWFIN53fRtef10ZNAmuvBZi6eIemLk5T+5ZN9PX9F7p0ojQA+LJGsWT91VdfVVJSkoKCgtSnTx99//33J7x36dKlslgsdR7btm3zYMXwRR1jwvTgsI769sEhWvLQEN01qG2dwCNJdw5MUkSwv3bmFOmLn/ebUCkA4ERMDT2zZ8/W/fffr0ceeUQbNmzQoEGDNGLECGVkZJz0ddu3b1dWVpbz0aFDh5PeD3hKeJC/7rmweqn8S9+mqeoUk6UBAJ5jauh54YUX9Mc//lF33XWXOnfurKlTpyo+Pl4zZsw46etatmypmJgY58NmY18UeI/b+icqMjRAe3KL9emGfWaXAwA4yrTQU1FRoXXr1mnYsGG1rg8bNkwrV6486Wt79+6t2NhYDR06VEuWLDnpveXl5SooKKj1ANypSaCf7j3a2zPtuzRV0tsDAF7BtNCTm5sru92u6OjoWtejo6OVnZ193NfExsbqtdde05w5czR37lx17NhRQ4cO1fLly0/4OVOmTFFERITzER/PuUtwv1uTE9W8SaAyD5Xqk6O7RAMAzGX6RObf7lxrGMYJd7Pt2LGj7r77bp177rlKTk7Wq6++qlGjRun5558/4ftPnjxZ+fn5zkdmZqZL6weOJzjApvuGVJ8cP/27nSqvsptcEQDAtNDTvHlz2Wy2Or06OTk5dXp/TuaCCy5QWlraCZ8PDAxUeHh4rQfgCTed30bR4YHad6RUH/10/LBtGIYcDp/aNQIATGPagaMBAQHq06ePFi1apN/97nfO64sWLdJVV1112u+zYcMGxcbGuqNE4KwE+ds09qL2+vtnmzV9yU6dlxSl9Lxi7TxYpF05xdp1sEi7DhbJZrXo0VFddF2f1qf1vlV2hxZvzVGP1hGKaxrs5t8CABoPU09ZnzRpkm655Rb17dtXycnJeu2115SRkaExY8ZIqh6a2rdvn9555x1J0tSpU5WYmKiuXbuqoqJC7777rubMmaM5c+aY+WsAJzS6X7xmLt2l/fllGj71xHPPHvr4Z6X+ckSPXt5F/ifZWXpvbrEe+ChFGzKOqGVYoOaNHUDwAYDTZGroGT16tPLy8vTUU08pKytL3bp104IFC5SQkCBJysrKqrVnT0VFhR566CHt27dPwcHB6tq1q+bPn6+RI0ea9SsAJxXoZ9NfR3TSxA9TFORvVbsWTdS+ZZNa/12QmqWXvk3T26vStTWrUNNv6q2WYUG13scwDM3+KVNPfblFJRXV84NyCst156yf9Ml9/Y+7USIAeFpReZWeXbhNiVGhur1/otedQcgxFIAHFJdXKdjfdsJ/ABZtOaBJs1NUWF6l6PBAzbi5j85t00ySlFdUrr/NTdWiLQckSecnReqh4R1137vrlVtUriEdW+i/t/Z1+dljAHCmNu3L1+Uvr1BUaIDWPXapS9+7URxDAfiC0EC/k/4vnku7RGveuAFq37KJDhSUa/R/Vun9HzO0ZHuOhk/9Xou2HJC/zaLJIzrp/bsvUL/ESL1xW18F+Vu1dPtBPfHFZvnY/34B4IX25hVLkhKbh5pcyfERegAv0a5FE80bO0CXdY1Rpd3Qw5+m6o63flJuUbnOia5+7t7B7ZyHmPaMb6qpo3vLYpHeXZ2hN1bsMfk3AODr0vNKJEkJUSEmV3J8hB7AizQJ9NOMm8/Vn4d3VM12VXcMSNTn4waqa1xEnfsv6xajh0d0liT9a8FWfbP5+Bt7AoAn7Mk92tMT5Z09Pcx+BLyMxWLR2Ivaa/A5LWQYUvfWdcPOr901KEl784r13o8Zmvhhij66N/mUrzFTQVmlQvxtzEECGqF0hrcA1Ee3VhGnFV4sFouevLKrLjynhUor7brz7Z+UeajEAxWeuZ/2HlLy09/qqld+UElFldnlAHCxvUeHtxIZ3gLgLn42q165sbc6xYTpYGG5rpu5Utuyvetw3X1HSjXmf+tUXGHX5v0F+vtnm80uCYALFZVX6WBhuSQpwUuHtwg9QCMRFuSvWXecpw5HV4D9fuYq/bg776zeMz2vWB+vzdTOnKKzep+Siird/fZa5RVXKDEqRFaL9Mm6XzSHw1iBRqNmaCsyNEARwf4mV3N8hB6gEYmJCNLHY5LVL7GZCsuqdMuba/RVatYZvUd6XrFeXbpTo6Z9r8HPLdWfP9mo4VOX69F5qcorKj/jmgzD0EMf/6wtWQWKCg3Qe3dfoPsvOUeS9Oi8TWcdqAB4B29fuSUReoBGp2lIgP73x/N1aZdoVVQ59Kf31+t/q9NPeL9hGNp1sKhW0Hl24XZt3l8gm9WiTjFhsjsMvbs6Q0OeW6qZy3aprPL0T41/+budWpCaLX+bRTNv6aNWTYM19qL2GtA+SqWVdo17f/0ZvR8A71SzcivJS4e2JFZvAY1SkL9NM246V499tlkfrMnQY/M2KaegTJMure5hSc8r0ardeVp99HGg4FgPjs1qUf92URrZPVbDu8YoMjRAq3bl6Z/zt2jz/gI989U2vbs6XX8b0UmjusfKYjnxposLN2XrhUU7JEn/vLqb+iVGOj/jxdG9NPKlFdqWXagnv9iiKdd0r9fvancYqrQ7FORvq9frAbhGzfCWt87nkTiGwuxyALcyDEPTvt2pFxdXB4++Cc2070ipsvLLat0XYLPq/LaRtYLObzkchuZu2Kfnvt7mDEm94pvqip5xSm4bpU4xYbV2nd6aVaBrZ6xUSYVdt/dP1BNXdq3znivScnXLmz/KMKRpN/TWlT3jzuj323ekVDe+vloOw9Cnfxqg5k0Cz+j1AFznD/9ZpTV7Duml63vpql6tXP7+rvj+pqcHaMQsFosmXtJBLcIC9ei8VK1NPyxJ8rdZ1Du+mS5oF6UL2kbq3DbNTtlTYrVadF2f1hrZPUavL9+jmct2KSXziFIyj0iSmoX46/ykKCW3i1L31hGa8MEGlVTYNbB9cz06qvNx33Ngh+Yad1F7vfzdTk2es1HdW0Uo6TT39zhSUqHb3lzjnEfw9IKteuEPvU6vYQC43F4v35hQoqfH7HIAj/lhZ67W7j2svonNdG6bZgoOOLvhoAMFZZq7fp9W7c7T2r2HnKe//1pCVIg+GztATUPq9hzVqLI7dON/f9SaPYfUJTZcc//U/5QBrKzSrpv++6PWpR9W8yYByiuukGFIH9x9gZLbRZ3V7wXgzJVUVKnL37+WJP3892GKCHH96i1XfH8TegCctUq7Qxt/OaJVu/KOhqDDCgmw6aN7k9UhOuyUr8/OL9PIad/rUHGFkttG6bnf91DrZsdfAVJld+i+99Zr0ZYDCg/y08dj+ut/q/fq3dUZatciVF9NvFABfqzRADxpy/4CjZz2vZqG+Cvl78Pc8hmcsg7AK/jbrOqTEKlxF3fQe3ddoNQnhmvV5KGnFXik6qX2L13fS0H+Vq3anafhLy7Xez+m1zk53jAM/f3zzVq05YAC/Kx6/da+6hgTpj8P76TmTQK062CxXv9+tzt+RQAn4Tx+wouHtiRCDwA3CPCznvFqqkEdWuiriReqb0IzFVfY9cinm3Trm2u070ip856Xv9up93/MkMUiTbu+l85vWz2UFRHsr0dHdZEkTfs2TRl57jmGY/P+fG3PLnTLewMNmbcfP1GD0APAayQ1D9Xse5P16KjOCvSz6vu0XA1/cbk+WJOhD9ZkOJe/P3VlV13WLbbWa6/qFaf+7aJUXuXQ3z/fVKeX6GytSz+sK6f/oMteWq5/f7NdVXaHS98faMhqJjF783J1idADwMvYrBbdNaitvpo4SH0SmqmovEqT56Zq8txUSdK4i9rrluTEOq+zWCz6x9XdFGCzaun2g1q4KdtlNRWXV+mB2SmyOwwZRnWP0x/+s8prD3YFPG3v0eGt0119aRZCDwCv1LZFE310b7IeGdnZOTH5931a68Fh55zwNe1aNNGYwW0lSU9+sUVF5a45yf2f87co41CJ4iKC9Oy1PRQW6Kf1GUc0ctr3+nLj/uO+psru0PIdBzXpoxSNmva9Nu3Ld0ktgDdqCEdQSOzTA8CL2awW3X1hW13aJVqb9xdoeNfok+4ALUl/uqi9Pvt5v9LzSvTioh167PIuZ1XDoi0H9MGaTFks0r//0EvJ7ar3Iprw4QZtyDiice9v0Iq0XP39ii4K9rdp4y/5mpeyT1/8nKXcX51V9sinqZo3dsAp6wcamtIKu7ILqjc89faJzIQeAF4vsXmoEk+z2zzI36anruqm295co7d+2KO+Cc0UGRogu2HI4ZDshiG7w6FAP5v6JUaedHl7blG5/jZnoyTp7kFtnXsAxUeG6KN7k/XS4jS9snSnPvwpUz/uOSTp2PlDUvWGjSO6x+qzDfv08y/5mp+apct7nNmu04C3Sz9U/Xc+IthfzY6zm7s3IfQAaHQGn9NCo3rEav7GLN333voT3tcpJkwv/KGXusTV3fPDMAz9bc5G5RVXqFNMWJ1hNX+bVQ8N76j+7aP0wOwUZ9gJ9rfp0i7Rurp3nAZ1aCF/m1XRYUF6cfEOPbtwu4Z1iTmrfYTSDhTqzR/2alT3WA3s0Lze7wO4yt7chrFySyL0AGikHr+8iw7kl+lgUblsVotsFkv1f48+0vNKtC27UFe9skITh3bQmMHt5Gc7FkZm/5SpxVtzFGCz6sXRvRTod/wl+P3bNddXEy/UrJV7ldQ8RMO6xCg0sPY/rXcNStK7P6Yr41CJ3v8xXbcPSDrj38cwDL2/JkP/+HKLyiod+vCnDI27qL3uv+Qc2awMmcE8exvAQaM1CD0AGqWW4UH65L7+J3w+t6hcj3yaqq83H9Dz3+zQoi0H9O8/9FT7lmHam1usp77cIkl6aPg56hx78t1fI0MDnCfYH09ooJ/uv6SDHvl0k6Z9t1PX9Gmt8KDT36b/SEmF/jYnVQs3V69Ia9siVLsPFuvl73bqp72HNO363moZHnTa7we4knNjQi9fuSWxeguAj2reJFAzb+6jqaN7KTzITz//kq+R01bo9eW7NemjFJVU2HVB20jdNbCtSz5vdN94tW0RqkPFFfrPsl2n/bofd+dpxEvfa+HmbPnbLHpkZGctfmCwXrq+l0IDbFq9+5BGTluhlTtzXVInTqywrFIOh0+d3HRa9jgPGvX+4S1CDwCfZbFYdHXvVvrmgcEafE4LVVQ59K8FW7U+44jCAv30/O97yuqioSM/m1V/u6yTJOmNFXuUnV920vur7A69sGiHbnh9tbLyy5TUPFRz7xuguy9sK6vVoqt6tdLn4weqU0yYcovKdfMbP2rat2mym/ylbBiGlmzL0ZJtOS7fINJMGzIOK3nKdxo+dTn7M/3GseXq9PQAgNeLiQjSrDv6aco13RV69PT5J6/qesJDT+vr0i7R6pvQTGWVDr14dHfp49mZU6TRr63WtG/T5DCk6/q01pfjB6p764ha97Vr0USf/mmA/tC3tRyG9MKiHbr9rTW1VpB5UnZ+me5+Z63umPWT7pj1k66dsVLr0g+bUosr5ZdUatz7G1RUXqW0nCJdM2OlNu9n3yVJKqu0K+togPf2jQklTlk3uxwAXianoExZ+WXqGd/ULe+/Lv2wrp2xUlaLtPD+C3XOrw5lLa+ya+bS3XplyU5V2B0KC/TTP3/XTVf1anXK9/1k3S96dF6qyiodslqkq3u30oSLO3hknoVhGJr9U6b+tWCrCsuq5G+zyM9qVWmlXZI0snuM/jK8U4OY8/FbhmHonv+t06ItB9QmMkTB/jZtP1CoJoF+eu2WPurf3rdX0G3PLtTwqcsVFuSnjY8Pc+s+VJyyDgAu1jI8yG2BR5L6JDTTZV1j5DCk//tqm/P6T3sPadS0FXpx8Q5V2B0a0rGFvrp/0GkFHulYb9DFnVrKYUhz1+/T0BeW6c8f/3zSA1hLKqq0NatAuw4W1WsH68xDJbrljTX629xUFZZVqWd8U305fpCW/nmIRveNl9UiLUjN1qUvLtOTX2zW4eKKM/4MM731w14t2nJAATarXrnxXH00JlnnJ0WqqLxKt721Rp//fPwduX3F3l+drt4QNt6kpwcAPGz3wSJd+uJy2R2GXrulj5buOKj3f8yQJDVvEqDHr+iqy3vE1vtLJCXziKYu3qGl2w9KkvysFl17bmsN6xqtjEMl2n2wWLtzi7T7YLFzaKJGaIBN0eFBahkeWP3fsEA1Cw1Q0+AANQ3xV0Rw9aNpiL8WbTmgZxduV2mlXYF+Vj00rKPuHJhUawn9tuwCTVmwTct2VNcSFuSnv1zWSTef3+a0fr8qu0Ovf79He3OL9cjlnc9o1dvZ+jnziK6buVKVdkNPXNHFudVAWaVdD370s+anZkmSHh3VWXcNcs2E94bmteW79PSCbbqiZ5xevqG3Wz/LFd/fhB4AMMGj81L17uqMWteu7xevv43opKYhrtnVdn3GYU1dnKblRwPHiUQE+8vhMFRYz7PKzk+K1P9d2+Okw1ffpx3U0wu2aWtWgaTqIa9nru1x0hBzoKBMEz7Y4Nzt+oK2kZp1x3kK8j/+nkmnK/WXfC1PO6iresWdcN5WfmmlLn/5e2UeKtVlXWM04+Zza4U0h8PQU19u0ayVeyVJdw1M0sMjO7ts4ntDMXluqj5Yk6HxF7fXg8M6uvWzCD31QOgB4A0OFpZryHNLVFxhV9vmoXr6mu66oG2UWz5rXfohvbpkl345XKrE5iFKat5EbVuEql2LULVt3sR5dEBxeZVyCst1oKBMBwrKlFNQ/ecjpZXKL61UfkmljpRW6EhJpY6UVio0wKYHh3XUjee1Oa0ve7vD0Fs/7NH/LdymSruh+MhgvXLjuerRummde5fvOKgHZqcor7jCObm8uMKukd1j9PIN59ZrQ8aCskr9++vtemd1ugxD8rdZ9Pu+8Rp7UXu1ahrsvM8wDN337not3Jyt1s2CNX/CIEUE1w1nhmHoteW7NeXoMGXzJoEa0rGFLurYUgM7ND/uaxqbG19frZW78vT873vquj6t3fpZhJ56IPQA8Bbr0g8r7UChru7d6qx7L8xgGEa9huBSMo9o3Pvr9cvhUvnbLJo8orPuGJAoi8WiKrtDU4+eaWYYUufYcL1yY29l55fptrfWqNJu6LbkBD1xZdfT/mzDMLQgNVtPfrFZOYXVh8B2aNlEaTlFkqrDz+h+8frTkPaKaxqst1fu1eOfb5a/zaKPx/RXr1PM8Zq3YZ8e+2yTCsuO9ZTZrBb1TWimizq1VL/EZqqyGyqpsKukwq7iiiqVlFeppNKuVk2DdVm3mBPu+G2W/UdK9dYPe/TzL/l6+nfd1b5lk+Pe13/Kt9qfX6Y59yWrT0KkW2si9NQDoQcAzJdfWqm/fPKzvt58QJI0rEu0HhreUY9+uklr9lYPZ910fhs9dnkXZyD84uf9Gv/BBknSn4d31NiL2p/yczIPleixzzY55zclNQ/VP67qpoEdmmvNnkOauniHVu7KkyQF2Ky6slecPk/Zrwq7Q49d3kV/HHh6R4ZUVDm0du8hfbctR0u252jXwdPfNqBlWKBuH5Com85LUESIub1Dm/fn6/Xlu/XlxixVHd3z6aKOLfTWHefVubes0q5Ojy2UJK199BI1bxLo1toIPfVA6AEA72AYht5euVdPL9imCrvDeb1JoJ+mXNNdV/SseyL9myv2OI8Iefa6HvpD3/jjvveh4gp9sCZDL3+XprJKhwJsVo0Z0k5/GtKuTq/a6t15mrp4h1bvPuS8dmmXaL12S596TybPyCvRku05+m5bjtIOFCoowKbQAD8FB9gUGmBTSKCfgvxs+mFnrrILqieThwTYdH2/NrpzYKLL94g6GcMw9H1arl5bvlsrfrWz93lJkVq795AchvTFuLr7RKUdKNSlLy5Xk0A/pT7h3uXqEqGnXgg9AOBdUn/J19j31yvjUIm6xIbrlZvOPelGd898tU0zl+2SzWrRa7f00dDO0ZKkvbnFWrTlgBZtOaC16dVf1pKU3DZK//xdN7VrcfwhmhqrduU590h67ZY+LptQfjIVVQ598fN+vf79bm3LLpRUPTQ2snusxgxuq65xEad4h9rySyt1uLhCh0uOPoornX8uKqtSWaVDZVV2lVXaq/9cadeBgjLtPbqtQc1n3zOorbq3jtADs1P06YZ9urRLtF6/tW+tz/pmc7bu+d86dWsVri/HD3JNg5wEoaceCD0A4H2Kyqv0095DSm4bdcr5TYZh6KGPN2rO+l8U5G/VDee10Yq0XOccnRpd48L1x4FJ+l3vVl6/h4xhGFqelqvXf9PbclnXGN1/aQd1ijnx91V5lV2fp+zXGyv2OIPTmQoJsGl0v3jdOSBJ8ZHHepl25hTp0heXyTCkBRMGqUvcsTpeX75b/1qwVaN6xOqVG8+t1+eeCVd8f3PKOgDAdE0C/XRRx5anda/FYtEz13bXoeJyLdl+UG/9sFdS9X5E57eN1LAuMbqkS3StFVnezmKxaPA5LTT4nBbavD9fM5ft1pcb92vh5mwt3JytUd1jNfGSDrV28D5cXKF3V6fr7VXpyi0qd14PCbCpWUiAmoX6V/83JEDNQvwVFuSvIH+rgvxtv3pYFRJgU582kcedT9S+ZRON6h6rLzdmafqSNL16Ux/nczUbEyY1gDO3ahB6AAANjr/NqlduOlePztukiiqHLu0SrSEdWzaKZeJd4yL08g29Nf7i9nrp2zTN35il+alZWrApS5f3iNP1/eK1IDVLc9b/orLK6rlQMeFBun1Aoq7vF+/yYbnxF3fQlxuz9NWmbO04UOgMXjWhJ6EBnK5eg+EtAAC82NasAr20OE0LN2fXea5rXLjuHtRWo3rEyt/mvpOlxvxvnRZuztaVPeM07ejOywOe+U77jpTq4zHJ6pfo3uXqEsNbAAA0ep1jwzXzlj7avD9fUxenaUVarga0j9IfB7bVBW0jPTJfafzQ9lq4OVtfbtyviZd0UOtmwdqfXyqp+tythoLQAwBAA9A1LqLOCipPfvYlnVtq8dYcvbJkp/40pJ0Mo/qstuZN3L/KzVU4ZR0AAJzS+Is7SJI+S9mvZTuqV5glNJDT1WsQegAAwCn1jG+qwee0kN1h6MVFOyTppPspeSNCDwAAOC0Thlb39hSVV58z1pBWbkmEHgAAcJr6JDTTgPZRzp8b0iRmidADAADOwISjc3skKbGBDW+xegsAAJy289tG6fp+8dp1sEg9Wp/Z2WBmI/QAAIAz8sy1PcwuoV4Y3gIAAD6B0AMAAHwCoQcAAPgEQg8AAPAJhB4AAOATCD0AAMAnEHoAAIBPIPQAAACfQOgBAAA+gdADAAB8AqEHAAD4BEIPAADwCYQeAADgEwg9AADAJ/iZXYCnGYYhSSooKDC5EgAAcLpqvrdrvsfrw+dCT2FhoSQpPj7e5EoAAMCZKiwsVERERL1eazHOJjI1QA6HQ/v371dYWJgsFotL37ugoEDx8fHKzMxUeHi4S9+7oaEtaqM9jqEtjqEtjqEtaqM9jqlpi4yMDFksFsXFxclqrd/sHJ/r6bFarWrdurVbPyM8PNzn/5LWoC1qoz2OoS2OoS2OoS1qoz2OiYiIOOu2YCIzAADwCYQeAADgEwg9LhQYGKjHH39cgYGBZpdiOtqiNtrjGNriGNriGNqiNtrjGFe2hc9NZAYAAL6Jnh4AAOATCD0AAMAnEHoAAIBPIPQAAACfQOhxkVdffVVJSUkKCgpSnz599P3335tdkkcsX75cV1xxheLi4mSxWDRv3rxazxuGoSeeeEJxcXEKDg7WkCFDtHnzZnOKdbMpU6aoX79+CgsLU8uWLXX11Vdr+/btte7xlfaYMWOGevTo4dxYLTk5WV999ZXzeV9ph+OZMmWKLBaL7r//fuc1X2qPJ554QhaLpdYjJibG+bwvtYUk7du3TzfffLOioqIUEhKiXr16ad26dc7nfaU9EhMT6/y9sFgsGjt2rCQXtoOBs/bhhx8a/v7+xuuvv25s2bLFmDhxohEaGmqkp6ebXZrbLViwwHjkkUeMOXPmGJKMTz/9tNbzzzzzjBEWFmbMmTPHSE1NNUaPHm3ExsYaBQUF5hTsRsOHDzfeeustY9OmTUZKSooxatQoo02bNkZRUZHzHl9pj88//9yYP3++sX37dmP79u3Gww8/bPj7+xubNm0yDMN32uG31qxZYyQmJho9evQwJk6c6LzuS+3x+OOPG127djWysrKcj5ycHOfzvtQWhw4dMhISEozbb7/d+PHHH409e/YYixcvNnbu3Om8x1faIycnp9bfiUWLFhmSjCVLlhiG4bp2IPS4wHnnnWeMGTOm1rVOnToZf/vb30yqyBy/DT0Oh8OIiYkxnnnmGee1srIyIyIiwpg5c6YJFXpWTk6OIclYtmyZYRi0R7NmzYz//ve/PtsOhYWFRocOHYxFixYZgwcPdoYeX2uPxx9/3OjZs+dxn/O1tvjrX/9qDBw48ITP+1p7/NrEiRONdu3aGQ6Hw6XtwPDWWaqoqNC6des0bNiwWteHDRumlStXmlSVd9izZ4+ys7NrtU1gYKAGDx7sE22Tn58vSYqMjJTku+1ht9v14Ycfqri4WMnJyT7bDmPHjtWoUaN0ySWX1Lrui+2RlpamuLg4JSUl6frrr9fu3bsl+V5bfP755+rbt69+//vfq2XLlurdu7def/115/O+1h41Kioq9O677+rOO++UxWJxaTsQes5Sbm6u7Ha7oqOja12Pjo5Wdna2SVV5h5rf3xfbxjAMTZo0SQMHDlS3bt0k+V57pKamqkmTJgoMDNSYMWP06aefqkuXLj7XDpL04Ycfav369ZoyZUqd53ytPc4//3y98847+vrrr/X6668rOztb/fv3V15ens+1xe7duzVjxgx16NBBX3/9tcaMGaMJEybonXfekeR7fzdqzJs3T0eOHNHtt98uybXt4HOnrLuLxWKp9bNhGHWu+SpfbJtx48Zp48aNWrFiRZ3nfKU9OnbsqJSUFB05ckRz5szRbbfdpmXLljmf95V2yMzM1MSJE/XNN98oKCjohPf5SnuMGDHC+efu3bsrOTlZ7dq109tvv60LLrhAku+0hcPhUN++ffX0009Lknr37q3NmzdrxowZuvXWW533+Up71HjjjTc0YsQIxcXF1bruinagp+csNW/eXDabrU7azMnJqZNKfU3Nigxfa5vx48fr888/15IlS9S6dWvndV9rj4CAALVv3159+/bVlClT1LNnT7300ks+1w7r1q1TTk6O+vTpIz8/P/n5+WnZsmWaNm2a/Pz8nL+zr7THb4WGhqp79+5KS0vzub8bsbGx6tKlS61rnTt3VkZGhiTf+zdDktLT07V48WLdddddzmuubAdCz1kKCAhQnz59tGjRolrXFy1apP79+5tUlXdISkpSTExMrbapqKjQsmXLGmXbGIahcePGae7cufruu++UlJRU63lfa4/fMgxD5eXlPtcOQ4cOVWpqqlJSUpyPvn376qabblJKSoratm3rU+3xW+Xl5dq6datiY2N97u/GgAED6mxrsWPHDiUkJEjyzX8z3nrrLbVs2VKjRo1yXnNpO7hkmrWPq1my/sYbbxhbtmwx7r//fiM0NNTYu3ev2aW5XWFhobFhwwZjw4YNhiTjhRdeMDZs2OBcrv/MM88YERERxty5c43U1FTjhhtuaJTLLQ3DMO677z4jIiLCWLp0aa2llyUlJc57fKU9Jk+ebCxfvtzYs2ePsXHjRuPhhx82rFar8c033xiG4TvtcCK/Xr1lGL7VHg8++KCxdOlSY/fu3cbq1auNyy+/3AgLC3P+e+lLbbFmzRrDz8/P+Ne//mWkpaUZ7733nhESEmK8++67znt8qT3sdrvRpk0b469//Wud51zVDoQeF3nllVeMhIQEIyAgwDj33HOdy5QbuyVLlhiS6jxuu+02wzCql1w+/vjjRkxMjBEYGGhceOGFRmpqqrlFu8nx2kGS8dZbbznv8ZX2uPPOO53//9CiRQtj6NChzsBjGL7TDify29DjS+1Rs7+Kv7+/ERcXZ1xzzTXG5s2bnc/7UlsYhmF88cUXRrdu3YzAwECjU6dOxmuvvVbreV9qj6+//tqQZGzfvr3Oc65qB4thGMZZ9EQBAAA0CMzpAQAAPoHQAwAAfAKhBwAA+ARCDwAA8AmEHgAA4BMIPQAAwCcQegAAgE8g9AAAAJ9A6AHgVkOGDNH9999vdhm1WCwWzZs3z+wyAHgYOzIDcKtDhw7J399fYWFhSkxM1P333++xEPTEE09o3rx5SklJqXU9OztbzZo1U2BgoEfqAOAd/MwuAEDjFhkZ6fL3rKioUEBAQL1fHxMT48JqADQUDG8BcKua4a0hQ4YoPT1dDzzwgCwWiywWi/OelStX6sILL1RwcLDi4+M1YcIEFRcXO59PTEzUP//5T91+++2KiIjQ3XffLUn661//qnPOOUchISFq27atHnvsMVVWVkqSZs2apSeffFI///yz8/NmzZolqe7wVmpqqi6++GIFBwcrKipK99xzj4qKipzP33777br66qv1/PPPKzY2VlFRURo7dqzzswA0DIQeAB4xd+5ctW7dWk899ZSysrKUlZUlqTpwDB8+XNdcc402btyo2bNna8WKFRo3blyt1z/33HPq1q2b1q1bp8cee0ySFBYWplmzZmnLli166aWX9Prrr+vFF1+UJI0ePVoPPvigunbt6vy80aNH16mrpKREl112mZo1a6affvpJH3/8sRYvXlzn85csWaJdu3ZpyZIlevvttzVr1ixniALQMDC8BcAjIiMjZbPZFBYWVmt46bnnntONN97onOfToUMHTZs2TYMHD9aMGTMUFBQkSbr44ov10EMP1XrPRx991PnnxMREPfjgg5o9e7b+8pe/KDg4WE2aNJGfn99Jh7Pee+89lZaW6p133lFoaKgkafr06briiiv0f//3f4qOjpYkNWvWTNOnT5fNZlOnTp00atQoffvtt85eJwDej9ADwFTr1q3Tzp079d577zmvGYYhh8OhPXv2qHPnzpKkvn371nntJ598oqlTp2rnzp0qKipSVVWVwsPDz+jzt27dqp49ezoDjyQNGDBADodD27dvd4aerl27ymazOe+JjY1VamrqGX0WAHMRegCYyuFw6N5779WECRPqPNemTRvnn38dSiRp9erVuv766/Xkk09q+PDhioiI0Icffqh///vfZ/T5hmHUml/0a7++7u/vX+c5h8NxRp8FwFyEHgAeExAQILvdXuvaueeeq82bN6t9+/Zn9F4//PCDEhIS9Mgjjzivpaenn/LzfqtLly56++23VVxc7AxWP/zwg6xWq84555wzqgmAd2MiMwCPSUxM1PLly7Vv3z7l5uZKql6BtWrVKo0dO1YpKSlKS0vT559/rvHjx5/0vdq3b6+MjAx9+OGH2rVrl6ZNm6ZPP/20zuft2bNHKSkpys3NVXl5eZ33uemmmxQUFKTbbrtNmzZt0pIlSzR+/HjdcsstzqEtAI0DoQeAxzz11FPau3ev2rVrpxYtWkiSevTooWXLliktLU2DBg1S79699dhjjyk2Nvak73XVVVfpgQce0Lhx49SrVy+tXLnSuaqrxrXXXqvLLrtMF110kVq0aKEPPvigzvuEhITo66+/1qFDh9SvXz9dd911Gjp0qKZPn+66XxyAV2BHZgAA4BPo6QEAAD6B0AMAAHwCoQcAAPgEQg8AAPAJhB4AAOATCD0AAMAnEHoAAIBPIPQAAACfQOgBAAA+gdADAAB8AqEHAAD4hP8HfQBAy0dwrx0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f1f6bc-f2ba-4b06-9109-7778966e1379",
   "metadata": {},
   "source": [
    "<h2 id=\"Question_3\">Question 3:Find the misclassified samples</h2> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a78f947-6f88-4871-8005-d5732cd8e2d9",
   "metadata": {},
   "source": [
    "<b>Identify the first four misclassified samples using the validation data:</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6d0864db-4423-447e-b379-407e707efb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample:  1 Predict value:  tensor(1)  & Actual Value:  tensor(0)\n",
      "Sample:  2 Predict value:  tensor(0)  & Actual Value:  tensor(1)\n",
      "Sample:  3 Predict value:  tensor(1)  & Actual Value:  tensor(0)\n",
      "Sample:  4 Predict value:  tensor(0)  & Actual Value:  tensor(1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(4):\n",
    "    print('Sample: ', i+1, 'Predict value: ', yhat[i], ' & Actual Value: ', y_test[i+1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715b8fe6-26bd-4bb9-b8da-1ca492528ee6",
   "metadata": {},
   "source": [
    "<a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/share-notebooks.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01\"> CLICK HERE </a> Click here to see how to share your notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f20a3f-7d1b-4aea-9e74-e373ec30e1bb",
   "metadata": {},
   "source": [
    "<h2>About the Authors:</h2> \n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb64cce-3fe5-489d-bced-79c3e7a447cf",
   "metadata": {},
   "source": [
    "\n",
    "## Change Log\n",
    "\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2020-09-21  | 2.0  | Shubham  |  Migrated Lab to Markdown and added to course repo in GitLab |\n",
    "\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a379170-e56f-40f9-9f8f-e3227416419a",
   "metadata": {},
   "source": [
    "Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01\">MIT License</a>.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
